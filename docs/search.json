[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantitative Methods 2",
    "section": "",
    "text": "Welcome"
  },
  {
    "objectID": "index.html#welcome-to-basc0005---quantitative-methods-data-science-and-visualisation",
    "href": "index.html#welcome-to-basc0005---quantitative-methods-data-science-and-visualisation",
    "title": "Quantitative Methods 2",
    "section": "Welcome to BASC0005 - Quantitative Methods: Data Science and Visualisation",
    "text": "Welcome to BASC0005 - Quantitative Methods: Data Science and Visualisation\nThis course teaches quantitative skills, with an emphasis on the context and use of data. Students learn to focus on datasets which will allow them to explore questions in society – in arts, humanities, sports, criminal justice, economics, inequality, or policy. Students are expected to work with Python to carry out data manipulation (cleaning and segmentation), analysis (for example, deriving descriptive statistics) and visualisation (graphing, mapping and other forms of visualisation). They will engage with literatures around a topic and connect their datasets and analyses to explore and decide wider arguments, and link their results to these contextual considerations. Below is an outline of the course:"
  },
  {
    "objectID": "notebooks/W10. Causal Inference.html#workshop-10-open-in-colab",
    "href": "notebooks/W10. Causal Inference.html#workshop-10-open-in-colab",
    "title": "Causal Inference",
    "section": "Workshop 10 ",
    "text": "Workshop 10 \n\nAims:\nThis workshop builds on last week’s material– now that we know what a basic regression looks like, we’ll be looking at three different types of regression that let us extract more robust and even plausibly causal insights from our data:\n\nPanel Regression\nDifference in Differences\nRegression Discontinuity\n\nOur focus area will be the United States, where we’ll be looking at the relationship between electoral outcomes, unemployment, and the minimum wage. We’ll also be bringing back material from previous weeks (particularly Week 3 - Spatial Data and Week 5 - Merging and Joining) to show how the different things we’ve learned fit together. First, as always, we must import the libraries we’ll need for this project.\n\n#!pip install linearmodels\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport plotly\nimport plotly.express as px\nimport warnings\nfrom statsmodels.formula.api import ols\nfrom statsmodels.iolib.summary2 import summary_col\nimport matplotlib.pyplot as plt\n\nwarnings.filterwarnings('ignore')\nsns.set(font_scale=1.5)\nsns.set_style(\"white\")\nplt.rcParams['figure.figsize'] = (12, 8)\n\nThis workshop is going to involve combining a number of different datasets:\n\nstate_data.csv: Monthly state-level unemployment data from the Bureau of Labor Statistics (BLS) spanning 1976-2022, and state-level minimum wage data from Kaggle spanning 1968-2020.\nelections.csv: county-level U.S. Presidential election results spanning 2000-2020 from the MIT Election Lab.\ngeojson-counties-fips.json: a county-level geospatial file used for making maps.\n\n\n!mkdir data\n!mkdir data/wk10\n!curl https://storage.googleapis.com/qm2/wk10/state_data.csv -o data/wk10/state_data.csv\n!curl https://storage.googleapis.com/qm2/wk10/elections.csv -o data/wk10/elections.csv\n!curl https://storage.googleapis.com/qm2/wk10/geojson-counties-fips.json -o data/wk10/geojson-counties-fips.json\n\nmkdir: data: File exists\nmkdir: data/wk10: File exists\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 2424k  100 2424k    0     0  4878k      0 --:--:-- --:--:-- --:--:-- 4917k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  875k  100  875k    0     0  2506k      0 --:--:-- --:--:-- --:--:-- 2529k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 3141k  100 3141k    0     0  6498k      0 --:--:-- --:--:-- --:--:-- 6558k\n\n\n\n\n\n\n\n\n## Panel Regression\n\n\n\n\nIntercept 65.608*** 74.605*** 68.971*** 73.383*** 70.706*** 81.721 (0.572) (0.684) (0.680) (0.727) (0.788) (0.797) unemployment -1.782 -2.351*** -1.891*** -1.618*** -1.101*** -2.322 (0.122) (0.114) (0.109) (0.088) (0.142) (0.114) population -0.021 -0.021*** -0.023*** -0.024*** -0.034*** -0.029 (0.001) (0.001) (0.001) (0.002) (0.002) (0.002) R-squared 0.118 0.172 0.148 0.165 0.142 0.230 R-squared Adj. 0.117 0.171 0.148 0.165 0.141 0.229 N 3113 3114 3114 3114 3115 3114 ========================================================================== Standard errors in parentheses.  p<.1,  p<.05, ***p<.01 ``` ::: :::\n\n\nThis table is pretty informative. Using what we learned from last week, we can say that for the 2020 election,\n\n\n* A 1% increase in the unemployment rate was associated with a 2.3% decrease in republican voteshare. * A 1000-person increase in population was associated with 0.029% decrease in republican voteshare. * both of these results are statistically signifiant at the 0.01 level. * 23% of the variation in republican voteshare can be explained by unemployment and population.\n\n\nCrucially, “increase” in this context pertains to differences in between counties!\n\n\nWe can also compare these results across different elections. The coefficient for the unemployment variable in 2020 is over twice the size of the same coefficient in 2016! So it looks like actually unemployment and republican voteshare are negatively related, contrary to popular belief.\n\n\nBut is this the whole story?\n\n\nBelow, i’ve isolated West Virginia, one of the states with the highest unemployment rates in America. Instead of drawing a new regression line every year, i’ve drawn a new regression line for each county over the six elections.\n\n\n::: {.cell execution_count=11}\n\n\n::: {.cell-output .cell-output-display execution_count=11}\n\n\n::: {.cell-output .cell-output-display}  ::: :::\n\n\nWithin a given county, an increase in the unemployment rate is associated with an increase in republican voteshare! This is where the second question comes in (variation within counties).\n\n\nWe got away with doing a series of cross-sectional analyses (a new regression for each election) because we have over 3000 counties, so \\(n>3000\\) for each of those regressions (though even so, we’re still splitting our data up and it would be better to leverage the full dataset of >18000 observations in one regression). It also provides relatively useful information about the importance of unemployment across the country for each election. We can’t really apply the same thinking to this situation, since we only have six time periods. If we ran a separate regression for each county, we would only have six observations per regression– nowhere near enough to satisfy the central limit theorem (at least n>30). The insights would also be of limited utility; we would get over 3000 unique estimates for the realtionship between county-level employment and election results. Imagine trying to fit that into one table.\n\n\nLuckily, there’s a way of modeling this relationship that allows us to account for differences in between counties, while also capturing the variation within counties. This is called a Fixed Effect regression\n\n\n> Fixed Effects Models: In experimental research, unmeasured differences between subjects are often controlled for via random assignment to treatment and control groups. Hence, even if a variable like Socio-Economic Status is not explicitly measured, because of random assignment, we can be reasonably confident that the effects of SES are approximately equal for all groups. Of course, random assignment is usually not possible with most survey research. If we want to control for the effect of a variable, we must explicitly measure it. If we don’t measure it, we can’t control for it. In practice, there will almost certainly be some variables we have failed to measure (or have measured poorly), so our models will likely suffer from some degree of omitted variable bias. >When we have panel data (the same people/states/counties. etc. measured at two or more points in time) another alternative presents itself: we can use the subjects as their own controls. With panel data we can control for stable characteristics (i.e. characteristics that do not change across time) whether they are measured or not. These include such things as sex, race, and ethnicity for individuals, or urban/rural, topography, economic structure for geographic areas. The idea is that, whatever effect these variables have at one point in time, they will have the same effect at a different point in time because the values of such variables do not change.\n\n\nA fixed effect regression takes the following form:\n\n\n\\[\\huge Y_{it}=\\alpha_i+\\beta X_{it}+\\epsilon_{it}\\]\n\n\nWhere: * \\(X_{it}\\) are the independent variables (e.g. population and unemployment) whose values vary over time. * \\(\\beta\\) is the slope coefficient for variable \\(x\\) (e.g. unemployment). The model assumes that these effects are time-invariant, e.g. the effect of \\(x\\) is the same at same 1 as it is at time 4 (although the value of \\(x\\) can be different at different time periods). * \\(\\alpha_i\\) and \\(\\epsilon_{it}\\) are both error terms. \\(\\epsilon_{it}\\) is different for each individual at each point in time. \\(\\alpha_i\\) only varies across individuals but not across time. We can think of \\(\\alpha_i\\) as representing the effects of all the time invariant/stable variables that have NOT been included in the model. So, given that we have 6 time periods for each county then the six records for county 1 would all have the same value for \\(\\alpha_1\\), the six records for county 2 would all have the same value for \\(\\alpha_2\\), etc. But, \\(\\epsilon_{it}\\) is free to be different for every case at every time period.\n\n\nA fixed effect regression allows us to account for \\(\\alpha_i\\) through a technique called demeaning\n\n\n>Demeaning: After demeaning, all variables for all cases have a mean of 0. That means that all the between-subject variability has been eliminated. All that is left is the within-subject variability. So, with a fixed effects model, we are analyzing what causes individual’s values to change across time. Variables whose values do not change (like race or gender) cannot cause changes across time (unless their effects change across time as well). However, whatever effect they have at one time is the same effect that they have at other times, so the effects of such stable characteristics are controlled.\n\n\nIn essence, you can picture this as allowing you to draw a separate regression line through each set of observations from the same group in your data (in this case, one county over time); however, while the intercept of these lines can vary (their absolute position), they will all have the same slope and will therefore be parallel. This is important, as we want to find one slope– one common effect of x– that fits all groups.\n\n\n::: {.cell execution_count=12} ``` {.python .cell-code} from linearmodels import PanelOLS from linearmodels import RandomEffects import statsmodels.formula.api as smf from linearmodels.panel import compare\n\n\ndf_c=df_c.set_index([‘county_fips’,‘year’]) # set the index to the county fips code and the year panel = PanelOLS.from_formula(‘r_votes ~ 1 + population + unemployment + EntityEffects’,df_c).fit() # run a fixed effects model print(compare({‘Fixed Effects’: panel,}, stars=True)) # print the model formatted as a regression table ```\n\n\n::: {.cell-output .cell-output-stdout} ``` Model Comparison ====================================== Fixed Effects\n\n\n\nDep. Variable r_votes Estimator PanelOLS No. Observations 18684 Cov. Est. Unadjusted R-squared 0.0227 R-Squared (Within) 0.0227 R-Squared (Between) -0.1949 R-Squared (Overall) -0.1627 F-statistic 180.40 P-value (F-stat) 0.0000 ===================== ============ Intercept 61.986 (246.29) population -0.0698 (-17.332) unemployment 0.2829*** (9.6749) ======================= ============== Effects Entity ————————————–\nT-stats reported in parentheses\n:::\n:::\n\n\nWhen accounting for time-invariant differences between counties, the effect of population remains negative. This suggests that counties in which the population is *decreasing* tend to experience an increase in republican voteshare. More specifically, for every 1000 people that leave a county, republican voteshare increases by 0.06%. \n\nThe really interesting part of this regression table, however, is the coefficient on the unemployment variable, which is now positive. This suggests that-- once we account for the differences between counties-- an increase in the unemployment rate *within* a county is *positively* associated with republican voteshare. Indeed, a 1% increase in the unemployment rate leads to a 0.28% increase in republican voteshare. \n\nThis regression output even gives us three separate $R^2$ values-- one for between-variation, another for within, and one overall. \n\n---------------------------\n## 2. Difference in Difference\n\nOne of the reasons that we observe a signficant relationship between unemployment and voting behaviour is that the Republican and Democratic parties have opposing views on what to do about unemployment. Democratic lawmakers have historically been in favour of increasing the minimum wage to benefit low-income workers, while Republicans have generally opposed this on the basis that it would hurt these very workers by increase unemployment. Indeed, classical economic theory holds that an increase in wages would lead to a reduction in employment; A business that makes $100k in revenue per year and spends all of it on employing 20 people can't suddenly start paying their workers double their salaries-- unless it fires half of its workers. This is obviously a simplified model though-- minimum wage laws typically don't double wages, and businesses don't operate at-cost, they turn a profit which they could use to pay their workers more. In the rest of this workshop, we're going to be investigating this question empirically: \n\n### Do minimum wage laws increase unemployment?\n\nNote that this is a *causal* question; i'm not asking if they're correlated-- i'm asking if one causes the other. The burden of proof here is much higher than observing correlations, and we have to think seriously about **endogeneity**. In partiuclar, we need to account for the influence of omitted variables (e.g. a recession, or the economic composition of a state), the potential for reverse causality (states implementing minimum wage laws in response to unemployment crises), and selection bias.\n\nIn a lab, you can conduct causal inference by running an experiment. You can randomly select individuals, split them into a control group and a treatment group, measure their values in an outcome variable prior to a treatment, administer a treatment, and measure their respective values after the treatment. If you observe a change in the outcome variable in the treatment group after having administered the treatment, you can interpert that as the causal effect of treatment. This is because we're able to make a plausible argument that the **control group can act as a counterfactual (a stand-in) for the treatment group in the absence of treatment**. Both groups had the same values before the treatment, then the only thing that changed between them was the treatment, so if we observe a change in the outcome variable, it must be due to treatment.\n\nIn the real world, we rarely get to run expermients of this kind. Instead, we have to hunt for **natural experiments**: situations in which there is a **treatment** which we're interested in measuring the effect of, and two groups that can plausibly act as a treatment and control group. \n\n> **[Difference in Difference](https://www.publichealth.columbia.edu/research/population-health-methods/difference-difference-estimation#:~:text=DID%20relies%20on%20a%20less,individual%20level%20is%20not%20possible.)** is a quasi-experimental design that makes use of longitudinal data from treatment and control groups to obtain an appropriate counterfactual to estimate a causal effect. DID is typically used to estimate the effect of a specific intervention or treatment (such as a passage of law, enactment of policy, or large-scale program implementation) by comparing the changes in outcomes over time between a population that is enrolled in a program (the intervention group) and a population that is not (the control group).\n\nThe Difference in Difference model can be estimated as a simple regression model of the following form: \n\n$$\\huge Y_{it} = \\beta_0 + \\beta_1 Treatment_i + \\beta_2 Post_t + \\beta_3 (Treatment_i \\times Post_t) + \\varepsilon_{it}$$\n\n- $Treatment_i$ is 0 for the control group and 1 for the treatment group\n- $Post_t$ is 0 for before and 1 for after\n\nwe can insert the values of $Treatment$ and $Post$ using the table below and see that coefficient ($\\beta_3$) of the interaction of $Treatment$ and $Post$ is the Difference in Differences (DID) estimator:\n\n|              | Control Group  | Treatment Group                    |    Difference              |\n|--------------|---------------------|-----------------------------------------|-----------------|\n| Before  | $\\beta_0$           | $\\beta_0 + \\beta_1$                     | $\\beta_1$                |\n| After   | $\\beta_0 + \\beta_2$ | $\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3$ | $\\beta_1 + \\beta_3$                |\n| Difference   | $\\beta_2$           | $\\beta_2 + \\beta_3$                     | **$\\beta_3$** (DID) |\n\n\n[Card and Krueger (1994)](https://davidcard.berkeley.edu/papers/njmin-aer.pdf) found one such natural experiment, allowing them to estimate the causal effect of an increase in the state minimum wage on unemployment using a DiD model; In 1992, New Jersey raised the state minimum wage from \\$4.25 to \\$5.05 while the minimum wage in neighbouring Pennsylvania stayed the same at \\$4.25. \n   \n* Treatmeng Group: New Jersey \n* Control Group: Pennsylvania\n* Pre-Treatment Period: before 1992\n* Post-Treatment Period: after 1992\n\nThey conducted a survey of 384 fast-food restaurants across both states, right before and right after the law came into effect in New Jersey, asking them how many people they employed. They ran a Difference-in-Differences model, and found that the coefficient $\\beta_3$ was positive but not statistically significant. In other words, the average total employees per restaurant *increased* after the minimum wage increased, but this could have been due to random chance. \n\nThat was a long time ago. Things have changed since then, including the fact that we have access to a lot more data and computational power. Let's see if we can replicate Card and Krueger's results with more recent data. I've downloaded data on unemployment, minimum wage levels, and Gross Domestic Product at the state level going back to 1976. Let's have a look at minimum wages in New Jersey and Pennsylvania over time:\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ndf_s=pd.read_csv('data/wk10/state_data.csv', parse_dates=['date']) # read in the state-level data\ndid=df_s[df_s['state'].isin(['pennsylvania', 'new jersey'])] # subset the data to only include pennsylvania and new jersey\n\npx.line(did, x='date', y='minwage', color='state', title=\"Minimum Wages in New Jersey and Pennsylvania\") # plot the minimum wage over time\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n:::\nThe plot above sort of looks like a set of descending staircases; this is for two reasons. The plateaus exist because each row in the dataframe df_s is the value of a state in a given month, but we only have minimum wage data for every year. So we get 12 consecutive values of minimum wage every year. The reason that the staircases are descending is because these minimum wages are adjusted for inflation. No matter where you’re from, you’ve probably heard a grandparent say something along the lines of “My parents would send me to the shops with 25 cents to buy groceries for the week”, but now it costs £9 for a bag of chips. That’s inflation– every year things tend to get slightly more expensive, so if the same absolute minimum wage actually diminishes in “real” terms, which is what the variable minwage measures. Incidentally, this is one of the main reasons University staff have been on strike. Anyway. Back to minimum wages.\nThis plot shows that for the past fifty years, New Jersey and Pennsylvania have had largely similar minimum wage policies. There have been a couple moments of divergence, including in the 1990s when the Card and Krueger study was conducted. However, the biggest divergence actually started taking place in 2014 when New Jersey seems to have begun taking a wildly different approach. While Pennsylvania has had the same minimum wage since 2008 (and therefore seen a decline in inflation-adjusted wages), New Jersey has raised the minimum wage significantly twice. In 2020, New Jersey’s minimum wage was around 50% higher than Pennsylvania’s. We can exploit the fact that these two states have historically had similar minimum wage laws but have recently experienced a big divergence to see if that change in minimum wages has resulted in a change in employment levels.\nOur Difference-in-Differences setup is as follows:\n\\[\\large Unemployment_{state, year} = \\beta_0 + \\beta_1 Treatment_{state} + \\beta_2 Post_{year} + \\beta_3 (Treatment_{state} \\times Post_{year}) + \\beta_4 GDP_{state,year} + \\varepsilon_{it}\\]\n\nNew Jersey is the treatment group\nPennsylvania is the control group\nYears before 2014 is the pre-treatment period\nYears after 2014 is the post-treatment period\n\n\ndid['post']=np.where(did['date']>='2014-01-01',1,0) # create a variable that is 1 if the date is after the minimum wage increase and 0 otherwise\ndid['treatment']=np.where(did['state']=='new jersey',1,0) # create a variable that is 1 if the state is new jersey (i.e., the treatment group) and 0 for pennsylvania (the control group)\ndid['post_treatment']=did['post']*did['treatment'] # create a variable that is 1 if the date is after the minimum wage increase and the state is new jersey and 0 otherwise\n\nBefore we proceed with the analysis, though, we need to satisfy two assumptions that will allow us to argue that Pennsylvania can act as a valid control group for New Jersey:\n\nNo simultaneous treatments:\n\nIf, for example, New Jersey suddenly entered a massive recession in 2014 as well, we couldn’t really argue that resulting effects on employment are due solely to the minimum wage law. To account for this, we’ll be including state-level GDP as an additional independent variable in our DiD model.\n\nParallel Trends:\n\nBoth states have to have been experiencing similar trends in the dependent variable (unemployment) prior to the treatment (minimum wage law). If they were trending in opposite directions for unobserved reasons, ensuing differences in unemployment may be due to those unobserved reasons rather than the treatment.\nWe can check this by plotting the dependent variable for both groups over time, and indicating the timing of the treatment.\n\n\n\ndid=did[(did['date']>='2008-01-01') & (did['date']<='2020-01-01')]\n\nsns.lineplot(data=did,x='date',y='unemployment',hue='state')\nplt.axvline(pd.to_datetime('2014-01-01'),color='black',linestyle='dashed', label='NJ Minimum Wage Increase')\nplt.title('Unemployment in Pennsylvania and New Jersey')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x174874b20>\n\n\n\n\n\nThis plot shows a big spike in unemployment occurring for both Pennsylvania and New Jersey as a result of the 2008 financial crisis. New jersey had a higher unemployment rate than Pennsylvania, but their trends are largely parallel and decreasing after 2012. In the years following the minimum wage law, New Jersey’s unemployment rate actually dips below Pennsylvania’s for the first time in years. Let’s look at this in the form of boxplots:\n\ndid['category']=did['treatment'].astype(str)+did['post'].astype(str) # this variable is just for the plot below\nsns.boxplot(x='category', y='unemployment', hue='treatment', data=did).set_xticklabels([\"Pre x Treatment\", \"Pre x Control\",'Post x Treatment','Post x Control']) \nplt.xlabel('')\nplt.title('Unemployment Rates by Treatment and Post Treatment')\nplt.show()\n\n\n\n\nThis plot is fascinating in and of itself. The two box plots on the left show the unemployment values of the counties prior to the minimum wage law in 2014, while the two on the right show their values after the minimum wage increases. Pennsylvania (the “control” group) is colored in blue, and New Jersey (the “treatment” group) is colored orange. Prior to the minimum wage increase in 2014, Pennsylvania (blue) has a lower unemployment rate than New Jersey (orange). In the years following New Jersey’s passage of the minimum wage law, New Jersey actually has a lower unemployment rate than Pennsylvania! This is the only boxplot where the “treatment” (a minimum wage law) is being applied, and it has the lowest unemployment rate.\nLet’s see if this difference is statistically signfiicant, and calculate a treatment effect:\n\ndid_model = ols('unemployment ~ gdp+ post + treatment + post_treatment', did).fit()\nprint(did_model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:           unemployment   R-squared:                       0.704\nModel:                            OLS   Adj. R-squared:                  0.699\nMethod:                 Least Squares   F-statistic:                     169.1\nDate:                Mon, 19 Dec 2022   Prob (F-statistic):           5.70e-74\nTime:                        09:20:32   Log-Likelihood:                -420.68\nNo. Observations:                 290   AIC:                             851.4\nDf Residuals:                     285   BIC:                             869.7\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n==================================================================================\n                     coef    std err          t      P>|t|      [0.025      0.975]\n----------------------------------------------------------------------------------\nIntercept         15.6515      1.277     12.254      0.000      13.137      18.166\ngdp            -1.343e-05   2.05e-06     -6.544      0.000   -1.75e-05   -9.39e-06\npost              -0.5845      0.307     -1.904      0.058      -1.189       0.020\ntreatment         -0.3641      0.295     -1.234      0.218      -0.945       0.217\npost_treatment    -1.9532      0.258     -7.581      0.000      -2.460      -1.446\n==============================================================================\nOmnibus:                      111.434   Durbin-Watson:                   0.319\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              320.366\nSkew:                          -1.772   Prob(JB):                     2.71e-70\nKurtosis:                       6.735   Cond. No.                     1.34e+07\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.34e+07. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n\nThere are some really interesting results from this model– let’s interpret the coefficients one by one.\n\ngdp: GDP is inversely related to unemployment. This makes sense: GDP basically measures the total amount of economic activity, so more economic activity = more employment.\npost: this coefficient is negative, but statistically insignificant at the 0.05 level; it indicates that unemployment generally decreased for both groups, but that this could be due to random chance.\ntreatment: again negative but insignficant, meaning that there is no significant difference in unemployment levels between NJ and PA over the entire period.\npost_treatment: this is our difference-in-differences estimator, and reflects the causal effect of treatment. It is negative and statistically significant. If we believe that the asusmptions of our model are satisfied, we can claim that:\n\nThe introduction of a minimum wage in New Jersey led to a 1.95% decrease in unemployment relative to Pennsylvania\n\n\nThis is a bold claim. We should do our best to back it up. Notice that i’ve sort of arbitrarily chosen a window of dates around the minimum wage law– maybe this result is a fluke, due to the timespan ive chosen.\nTo address this concern, I’ll run the same model 10 times, starting with a really small time window– just one year on either side of the law– and progressively expand it.\n\nmodels=[] # create empty list to store the models\nnames=[] # create empty list to store the names of the models\n\nfor window in range(1,10): # loop through years from 2000 to 2020 in increments of 4\n    did=df_s[(df_s['date']>=str(2014-window)+'-01-01') & (df_s['date']<=str(2014+window)+'-01-01') & df_s['state'].isin(['pennsylvania', 'new jersey'])] # subset the data within the window of interest around 2014\n    did['post']=np.where(did['date']>='2014-01-01',1,0) # create a dummy variable indicating the period after the minimum wage increase\n    did['treatment']=np.where(did['state']=='new jersey',1,0) # create a dummy variable for treatment\n    did['post_treatment']=did['post']*did['treatment'] # create an interaction term between the post and treatment variables\n    did_model = ols('unemployment ~ gdp+ post + treatment + post_treatment', did).fit() # run the difference in difference model\n\n    models.append(did_model) # append the model to the list of models\n    names.append('± '+str(window)+' Year') # append the name of the model to the list of names\n\ntable=summary_col( # create a regression table \n    models, # pass the models to the summary_col function\n    stars=True, # add stars denoting the p-values of the coefficient to the table; * p<0.05, ** p<0.01, *** p<0.001\n    float_format='%0.3f', # set the decimal places to 3\n    model_names=names, # set the names of the model\n    info_dict = {\"N\":lambda x: \"{0:d}\".format(int(x.nobs))}) # add the number of observations to the table\n\nprint(table) # print the table\n\n\n=======================================================================================================\n               ± 1 Year  ± 2 Year  ± 3 Year  ± 4 Year  ± 5 Year  ± 6 Year  ± 7 Year  ± 8 Year  ± 9 Year\n-------------------------------------------------------------------------------------------------------\nIntercept      21.423** 33.130*** 24.228*** 22.751*** 19.711*** 15.651*** 2.327     -0.580    -2.340*  \n               (9.399)  (2.324)   (1.333)   (0.876)   (0.746)   (1.277)   (2.183)   (1.579)   (1.398)  \ngdp            -0.000   -0.000*** -0.000*** -0.000*** -0.000*** -0.000*** 0.000**   0.000***  0.000*** \n               (0.000)  (0.000)   (0.000)   (0.000)   (0.000)   (0.000)   (0.000)   (0.000)   (0.000)  \npost           -0.619   0.100     -0.262    -0.256*   -0.483*** -0.585*   -2.277*** -2.792*** -3.205***\n               (0.411)  (0.194)   (0.162)   (0.140)   (0.154)   (0.307)   (0.576)   (0.501)   (0.479)  \ntreatment      -1.604   -3.686*** -1.850*** -1.466*** -0.903*** -0.364    1.825***  2.139***  2.241*** \n               (1.896)  (0.479)   (0.285)   (0.190)   (0.169)   (0.295)   (0.509)   (0.402)   (0.363)  \npost_treatment -0.837** -1.707*** -1.848*** -2.108*** -2.111*** -1.953*** -0.780*   -0.375    -0.030   \n               (0.323)  (0.158)   (0.134)   (0.115)   (0.130)   (0.258)   (0.469)   (0.426)   (0.409)  \nR-squared      0.856    0.934     0.938     0.952     0.933     0.704     0.194     0.167     0.165    \nR-squared Adj. 0.844    0.931     0.936     0.951     0.932     0.699     0.184     0.158     0.157    \nN              50       98        146       194       242       290       338       384       408      \n=======================================================================================================\nStandard errors in parentheses.\n* p<.1, ** p<.05, ***p<.01\n\n\nThe row we’re mainly interested in is the post_treatment coefficient, the treatment effect. It remains significant and negative in all time periods smaller than 8 years, after which point it becomes insignificant;\nHow do you think this affects our conclusion?\n\n\n\n## Regression Discontinuity\n\n\nOur difference in difference model made causal claims by treating PA as a control group for NJ on the basis that they had similar trends in unemployment before the minimum wage law, and diverging trends after, and no other shock coincided with this policy. We could still poke some holes in that– NJ seems to have fared worse than PA after the 2008 crisis; maybe more people work in finance in NJ. Indeed, Jersey City is across the water from Manhattan, America’s financial centre. Bankers would be hard hit by a financial crisis, but are probably not that affected by minimum wage laws. Conversely, Pennsylvania is the 3rd largest coal-producing state in the U.S.– coal miners are probably less affected by financial crises, but more likely to be earning minimum wage. As such, increasing the minimum wage in a place where most people are bankers probably has less of an effect on unemployment compared to an area where everyone is a coal miner.\n\n\nRunning a state-level analysis is subject to this sort of selection bias, since by looking at state averages we’re effectively comparing places like Jersey City to places like Centralia, a coal-mining town in central Pennsylvania which saw its population decline from 1000 in 1980 to just five residents in 2020. So the next step in our analysis might be to try to compare apples to apples. There are a number of ways of doing this– we could look at the unemployment rate by industry, for example. But what if we didn’t want to rely on pre-trends, or if we didn’t even have data prior to the treatment? This is often the case\n\n\nTo build a more valid counterfactual, we can drill even deeper to find even more similar comparison groups using a Regression Discontinuity Design (RDD) using county (rather than state) level data.\n\n\n> Regression Discontinuity Designs are a method of estimating treatment effects in a nonexperimental setting where treatment is determined by whether an observed “assignment” variable exceeds a known cutoff point. If the cutoff is exogenous to the treatment, observations in the vicinity of this cutoff are likely to be very similar, and assignment to the treatment or control group can be considered as good as random.\n\n\nRDD models generally take the following form:\n\n\n\\[\\huge Y_{i} = \\beta_0 + \\beta_1 X_i + \\beta_2 D_i + \\varepsilon_{i}\\] \\[\\large D_i=    \\begin{cases}\n1 & X_i>X_k\\\\\n0 & X_i<X_k\\\\\n\\end{cases} \\]\n\n\nIn our case, the treatment is the minimum wage law passed in NJ in 2014. We want to be looking at the period after this to pick up on any changes in employment. The assignment variable in this case could be the distance of a county to the border between the two states, and the sharp cutoff would be the border itself. Counties on the border counties are probably much more similar to each other than other, farther away counties: this would exclude both Jersey City (in the far east of NJ) and Centralia (in the centre of PA).\n\n\nIndeed, several cities are divided by the border between these states including Philladelphia, the capital city of Pennsylvania:\n\n\n::: {.cell execution_count=19}\n\n\n::: {.cell-output .cell-output-display execution_count=19}\n\n\n{=html} <script type=\"application/vnd.jupyter.widget-view+json\"> {\"model_id\":\"4e1431195538443db107698312564f13\",\"version_major\":2,\"version_minor\":0} </script>\n\n\n::: :::\n\n\nOn the left side of the river is Philladelphia, PA, while on the right side is Camden, NJ. The code below uses the county shapefile we used before to isolate the counties in NJ and PA that are on the border.\n\n\n::: {.cell execution_count=20} ``` {.python .cell-code} import geopandas as gpd\n\n\nshp = gpd.read_file(‘data/wk10/geojson-counties-fips.json’) # read in the counties shapefile\n\n\nsubset=shp[shp[‘STATE’].isin([‘34’,‘42’])] # new jersey = 34, pennsylvania = 42, new york = 36\n\n\nsubset[‘neighbors’]= 0 # create a new column called neighbors\n\n\nfor index, row in subset.iterrows(): # iterate through each row in the counties shapefile buffered= row[‘geometry’].buffer(0.1) # create a buffer around the county so that it overlaps with its neighbors neighbors = list(set(subset[subset.geometry.overlaps(buffered)].STATE.tolist()).difference([row.STATE])) # check which counties overlap with the buffer, grab the state code, and remove the current county’s state code subset.at[index, “neighbors”] = “,”.join(neighbors) # add the list of neighbors to the neighbors column\n\n\nsubset[‘border’]=np.where(subset[‘neighbors’]==’’,0,1) # create a new column called border that is 1 if the county is on the border and 0 if it is not\n\n\nsubset[‘viscol’]=subset[‘STATE’].astype(int)+subset[‘border’] # create a new column that combines the state code and the border column subset.plot(column=‘viscol’,legend=False, figsize=(20,10), cmap=‘RdYlGn’) # plot the counties and color them by the border column plt.title(‘Border Counties in New Jersey and Pennsylvania’, fontsize=20) # add a title ```\n\n\n::: {.cell-output .cell-output-display execution_count=20}\n\n\n::: {.cell-output .cell-output-display}  ::: :::\n\n\nThe plot above shows counties in Pennsylvania in green, and New Jersey in red. Dark green counties are border counties in PA, while light red counties are border counties in NJ. Under the assumption that these counties are going to be very similar to each other in most ways other than the fact that NJ implemented a minimum wage law, the simplest regression discontinuity desgin would basically just be a regression of the following form:\n\n\n::: {.cell execution_count=30} ``` {.python .cell-code} border_counties=subset[subset[‘border’]==1][‘id’].tolist() # create a list of the border counties rdd=counties[(counties[‘year’]>2007)&(counties[‘county_fips’].isin(border_counties))] # subset the counties data to only include border counties and years after 2007 rdd_model = ols(‘unemployment ~ C(state)’, rdd[rdd[‘year’]>2014]).fit() print(rdd_model.summary())\n\n\n```\n\n\n::: {.cell-output .cell-output-stdout} ``` OLS Regression Results ============================================================================== Dep. Variable: unemployment R-squared: 0.047 Model: OLS Adj. R-squared: 0.038 Method: Least Squares F-statistic: 5.078 Date: Mon, 19 Dec 2022 Prob (F-statistic): 0.0264 Time: 09:26:14 Log-Likelihood: -213.30 No. Observations: 105 AIC: 430.6 Df Residuals: 103 BIC: 435.9 Df Model: 1 Covariance Type: nonrobust ================================================================================== coef std err t P>|t| [0.025 0.975]\n\n\n\nIntercept 5.2054 0.249 20.910 0.000 4.712 5.699 C(state)[T.42] 0.8212 0.364 2.253 0.026 0.098 1.544 ============================================================================== Omnibus: 22.707 Durbin-Watson: 0.642 Prob(Omnibus): 0.000 Jarque-Bera (JB): 29.073 Skew: 1.166 Prob(JB): 4.86e-07 Kurtosis: 4.100 Cond. No. 2.55 ==============================================================================\nNotes: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. ``` ::: :::"
  }
]