{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oballinger/QM2/blob/main/notebooks/W03.%20Spatial%20Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPWQcV1rUG5R"
      },
      "source": [
        "# Spatiotemporal Data\n",
        "\n",
        "## *Workshop 3*  [![Open In Colab](https://github.com/oballinger/QM2/blob/main/colab-badge.png?raw=1)](https://colab.research.google.com/github/oballinger/QM2/blob/main/notebooks/W03.%20Spatial%20Data.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dq7jf9TUWEp"
      },
      "source": [
        "Sometimes the data we work with references points on the earth's surface, unlocking a rich set of analytical possibilities. In today's workshop, we're going to be exploring the effect of the 2020 California Wildfires on air quality across the state. We'll be using real air quality data collected by sensors and combining it with satellite imagery to show how toxic smoke from wildfires swept over America's largest state. \n",
        "\n",
        "### Aims\n",
        "- Understanding spatiotemporal data\n",
        "- Grouping data in pandas \n",
        "- Manipulating and plotting geographic data \n",
        "\n",
        "\n",
        "## Background\n",
        "\n",
        "![](https://image.cnbcfm.com/api/v1/image/106695701-1599664926959-gettyimages-1228423382-AFP_8PL8JF.jpeg?v=1599664969)\n",
        "\n",
        "The [2020 California wildfire season](https://en.wikipedia.org/wiki/2020_California_wildfires) was record-setting. By the end of the year, 9,917 fires had burned more than 4% of the state's area, making 2020 the largest wildfire season recorded in California's modern history. California's August Complex fire has been described as the first \"gigafire\", burning over 1 million acres across seven counties, an area larger than the state of Rhode Island. The fires destroyed over 10,000 structures and cost over \\$12.079 billion (2020 USD) in damages, including over \\$10 billion in property damage and \\$2.079 billion in fire suppression costs. The intensity of the fire season has been attributed to a combination of more than a century of poor forest management and higher temperatures resulting from climate change.\n",
        "\n",
        "The fires also had a [profound effect on air quality](https://epic.uchicago.edu/news/pollution-from-californias-2020-wildfires-likely-offset-decades-of-air-quality-gains/): “Places that are experiencing frequent or more frequent wildfires are going to experience higher air pollution levels, not just for a couple of days or weeks, but it could impact the annual level of exposure,” said Christa Hasenkopf, director of air quality programs at the University of Chicago institute. “It can bump up that average to unsafe and unhealthy levels that really do have an impact on people’s health. When we think of wildfires, we think of short-term events — and hopefully they are — but they can have long-term consequences considering your overall air pollution exposure.”\n",
        "\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "Let's begin by installing some libraries that we'll be working with today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "alY6eayO1uAY",
        "outputId": "95f42985-e0ca-4dd5-dbdd-41870f5986df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Basemap\n",
            "  Downloading basemap-1.3.4-cp37-cp37m-manylinux1_x86_64.whl (864 kB)\n",
            "\u001b[K     |████████████████████████████████| 864 kB 12.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.22,>=1.21 in /usr/local/lib/python3.7/dist-packages (from Basemap) (1.21.6)\n",
            "Collecting pyshp<2.4,>=1.2\n",
            "  Downloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting basemap-data<1.4,>=1.3.2\n",
            "  Downloading basemap_data-1.3.2-py2.py3-none-any.whl (30.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 30.5 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting pyproj<3.4.0,>=1.9.3\n",
            "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib<3.6,>=1.5 in /usr/local/lib/python3.7/dist-packages (from Basemap) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.6,>=1.5->Basemap) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.6,>=1.5->Basemap) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.6,>=1.5->Basemap) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.6,>=1.5->Basemap) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<3.6,>=1.5->Basemap) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from pyproj<3.4.0,>=1.9.3->Basemap) (2022.9.24)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib<3.6,>=1.5->Basemap) (1.15.0)\n",
            "Installing collected packages: pyshp, pyproj, basemap-data, Basemap\n",
            "Successfully installed Basemap-1.3.4 basemap-data-1.3.2 pyproj-3.2.1 pyshp-2.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipyleaflet\n",
            "  Downloading ipyleaflet-0.17.2-py3-none-any.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 9.7 MB/s \n",
            "\u001b[?25hCollecting traittypes<3,>=0.2.1\n",
            "  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting xyzservices>=2021.8.1\n",
            "  Downloading xyzservices-2022.9.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: branca>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from ipyleaflet) (0.5.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.7/dist-packages (from ipyleaflet) (7.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from branca>=0.5.0->ipyleaflet) (2.11.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (7.9.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (3.0.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (5.3.4)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (3.6.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipyleaflet) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipyleaflet) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipyleaflet) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipyleaflet) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipyleaflet) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipyleaflet) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipyleaflet) (2.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipyleaflet) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (5.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.13.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (4.11.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (5.7.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (23.2.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipyleaflet) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->branca>=0.5.0->ipyleaflet) (2.0.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (5.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.8.4)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (2.16.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (4.1.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (5.10.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.5.1)\n",
            "Installing collected packages: jedi, xyzservices, traittypes, ipyleaflet\n",
            "Successfully installed ipyleaflet-0.17.2 jedi-0.18.1 traittypes-0.2.1 xyzservices-2022.9.0\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "!pip install Basemap\n",
        "!pip install ipyleaflet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUe0JJqBV3VO"
      },
      "source": [
        "## Importing Libraries \n",
        "\n",
        "The first step in any python script is to import the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DArwH58V12Pu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pylab\n",
        "from datetime import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "pylab.rcParams['figure.figsize'] = (10, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2hLyKoeV665"
      },
      "source": [
        "## Downloading Data \n",
        "\n",
        "The next step is to import the data that we need for our analysis. This week we'll be using real data collected in 2020 by the [Environmental Protection Agency (EPA)](https://www.epa.gov/outdoor-air-quality-data/download-daily-data). I've generated a .csv file containing the data that I want using the dropdown menus. The EPA also has an [Application Programming Interface](https://aqs.epa.gov/aqsweb/documents/data_api.html) for air quality data, which you could use to pull in data directly into python without having to download a .csv!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDn-c1Qf3nZi"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "!mkdir data/wk3\n",
        "!curl https://qm2.s3.eu-west-2.amazonaws.com/wk3/california_aqi.csv -o ./data/wk3/california_aqi.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGrsndD29TKJ"
      },
      "source": [
        "Let's open the .csv file and have a look at it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6mmeCMO-Rsz"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('data/wk3/california_aqi.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4LMnPYTB0RP"
      },
      "source": [
        "Each row in this dataset is an individual reading from an air quality sensor. The first row is a reading from sensor number 60010007 on January 1st 2020. It is located in Alameda County, and recorded an Air Quality Index (AQI) reading of 36. So for each sensor (uniquely identified by the Site ID column) we will have 365 readings. We also have the latitude and longitude of each one of these air quality sensors. The presence of these fields makes this **spatio-temporal** data. We'll first analyze the temporal dimension of our data, before adding in the spatial dimension\n",
        "\n",
        "##  Temporal Data \n",
        "\n",
        "Before we go any further, we need to focus on a very special column in our dataset: the \"Date\" column. We'll be relying heavily on this dimension of our dataset. Whenever we have temporal data, the first thing we want to do is check whether pandas is storing it as datetime information or as a string (text). We can do this using the `dtype` function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZjdzhrW_XsV"
      },
      "outputs": [],
      "source": [
        "print('Prior to cleaning, the data type of the \"Date\" column is:', df['Date'].dtype)\n",
        "\n",
        "df['Date']=pd.to_datetime(df['Date'])\n",
        "\n",
        "print('Now, it is stored as: ', df['Date'].dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "folcag_kce9u"
      },
      "source": [
        "Once we've stored the Date column as datetime information, we can do all sorts of useful things with it. For example, we can quickly extract the month from the date, or even the \"day of year\" (i.e., how many days since January 1st of that year have passed). Try doing that in one line of code if your \"Date\" column is stored as text!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtCTajbNbULr"
      },
      "outputs": [],
      "source": [
        "# we can extract the month from the Date column and save it as a new column \n",
        "df['Month']=df['Date'].dt.month\n",
        "# we can do the same for the day of year. \n",
        "df['Day']=df['Date'].dt.dayofyear\n",
        "\n",
        "print(df[['Date','Month','Day']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmHh2SuZfAkY"
      },
      "source": [
        "When I print the new columns we've made (\"Month\" and \"Day\") next to the original \"Date\" column, we can see that everything is working as it should. First date (January 1st, 2020), has a value of 1 in the month column, and a 1 in the day column. The last row in the dataset was a sensor reading raken on December 29th, 2020. It has a month of 12, and day-of-year value of 364. Great."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-U0Qi3dc8TW"
      },
      "source": [
        "### Grouping Data\n",
        "\n",
        "We can now use the new temporal columns we've created to analyze our data further. The broadest possible question we're interested in today is \"What was the effect of the 2020 wildfires on air quality in California\". This involves looking at air quality over time, and comparing pre/post wildfire air quality reading. \n",
        "\n",
        "To translate that into python, we effectively want to calculate the average AQI value for all of the sensors in California each day. We can accomplish this using the `.groupby()` function in pandas. [Here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) is the documentation page for the function, give it a quick read. \n",
        "\n",
        "Remember, each row in our dataframe `df` is an individual sensor reading on a given day. We now want a datafram in which each row is *one day*, representing the average of *all AQI sensors*. We can accomplish that using hte following line of code, which has four parts:\n",
        "\n",
        "`df.groupby('Day')['AQI'].mean()`\n",
        "\n",
        "1. `df`: the dataframe we want to use\n",
        "2. `.groupby('Day')`: the groupby function, and the name of the column that we want to group our data by. In this case, we want each row in our new dataset to be one day, so we're using the \"Day\" column. \n",
        "3. `['AQI']`: the data that we want to aggregate. Remember, our dataframe has many columns, but we want to calculate the average daily value of AQI. \n",
        "4. `.mean()`: the method of aggregation. We're calculating the average in this case, but we could also want to take the maximum value (`.max()`), minimum value (`.min()`), median (`.median()`), etc. \n",
        "\n",
        "Let's look at the output from the line of code above. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0LJq1FyB1da"
      },
      "outputs": [],
      "source": [
        "#dataframe \n",
        "daily=df.groupby('Day')['AQI'].mean()\n",
        "daily"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnUimPW5hD2m"
      },
      "source": [
        "Now we can see that our dataframe has 366 rows (one for each day of the year, 2020 was actually a leap year!). Let's plot the daily average of the AQI sensors, along with a dashed vertical line indicating the day a State of Emergency was declared (August 18th). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_LznYgJjAdu"
      },
      "outputs": [],
      "source": [
        "# plot the daily data\n",
        "daily.plot(color='red')\n",
        "\n",
        "#add title and axis labels\n",
        "plt.title('Daily Air Quality Index readings in California, 2020')\n",
        "plt.ylabel('AQI')\n",
        "plt.xlabel('Day of Year')\n",
        "\n",
        "# add a dashed black line on August 18th (the 231st day of the year)\n",
        "plt.axvline(231, color='black', linestyle='--', label='State of Emergency')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24q4Noc3jSRZ"
      },
      "source": [
        "Pretty cool! We can clearly see some spikes in AQI that correspond directly to when the state of emergency was declared. Our data is matching expectations about reality: even though there's no information about the state of emergency or the wildfires in our dataframe (remember, it's just a bunch of air quality readings from sensors), we observe a relationship between our variables (presence of wildfires and air quality) that conforms to our expectations.\n",
        "\n",
        "### Exercise \n",
        "Now, repeat the above plot but aggregate the dataframe by month rather than by day. Store the monthly data as a new dataframe called \"monthly\". "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NonkXQSCjZZV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUp_C4_Il3se"
      },
      "source": [
        "### Geographic Disparities\n",
        "\n",
        "OK. We've got a good sense of how the wildfires affected air quality readings across the whole state. But California is huge; there are probably geographic disparities in how bad air quality was as a result of the fires. Let's see which counties were worst affected by the wildfires.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3fIoMxfm1Fy"
      },
      "source": [
        "In our original dataframe, each row was a reading from a given sensor on a given day. We grouped this data by day to create a dataframe that took the average of *all* sensors in california for each day as follows:\n",
        "\n",
        "`df.groupby('Day')['AQI'].mean()`\n",
        "\n",
        "\n",
        "Now, we want to plot the average daily air quality by county; this will involve aggregating both by day *and by county*. Intuitively, we can accomplish this changing `'Day'` to `['Day','COUNTY']`, like so:\n",
        "\n",
        "`df.groupby(['Day','COUNTY'])['AQI'].mean()`\n",
        "\n",
        "Let's store this new dataframe and call it \"county_daily\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO6D8u82naTR"
      },
      "outputs": [],
      "source": [
        "county_daily=df.groupby(['Day','COUNTY',])['AQI'].mean().reset_index()\n",
        "county_daily"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbfS8_kToxiz"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Using the `groupby` function, create a new dataframe called \"counties\" in which each row is a county, and each value is the **maximum** AQI value in that county during the entire year. Then, sort this dataframe in descending order using `.sort_values(ascending=False)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEMD4htxGe2E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5G647PCp76L"
      },
      "source": [
        "Which county had the highest maximum AQI value? Which county had the lowest? store the names of these counties as varables called \"highest\" and \"lowest\", shown below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiGZhFDNqD-W"
      },
      "outputs": [],
      "source": [
        "highest=''\n",
        "lowest=''\n",
        "\n",
        "# Filter the county-level daily AQI readings for the worst-affected county\n",
        "worst_county=county_daily[county_daily['COUNTY']==highest]\n",
        "\n",
        "# Filter the county-level daily AQI readings for the least-affected county\n",
        "best_county=county_daily[county_daily['COUNTY']==lowest]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3hO0ZYrsmGk"
      },
      "source": [
        "Using those two variables, lets plot the AQI values for each of these counties individually: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heQT9nIHCcXD"
      },
      "outputs": [],
      "source": [
        "# plot the data from the worst affected county\n",
        "plt.plot(worst_county['Day'], worst_county['AQI'], label=highest)\n",
        "\n",
        "# plot the data from the least affected county\n",
        "plt.plot(best_county['Day'], best_county['AQI'], label=lowest)\n",
        "\n",
        "#add title and axis labels\n",
        "plt.title('Daily Air Quality Index readings in California, 2020')\n",
        "plt.ylabel('AQI')\n",
        "plt.xlabel('Day of Year')\n",
        "\n",
        "# add a dashed black line on August 18th (the 231st day of the year)\n",
        "plt.axvline(231, color='black', linestyle='--', label='State of Emergency')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG59Z2oUtKdd"
      },
      "source": [
        "We can see that the worst affected county suffered a massive spike in AQI following the wildfires, while the least affected county experienced a much smaller increase in AQI. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY-Spc41t2E3"
      },
      "source": [
        "## Bringing in Geography \n",
        "\n",
        "We can explore some limited geographic variation using the \"COUNTY\" column in our dataframe. But we actually have the latitude and longitude of each individual sensor. We can visualize latitude and longitude data quite simply as a scatterplot. \n",
        "\n",
        "Remember, in our original dataframe each row is a reading from a given sensor on a given day. The sensor's location does not vary over time, so if we simply plot our original dataframe, we'll have loads of points on top of each other. Let's pick a specific date, take a slice of our dataframe on that one date, and plot it. I've picked September 9th based on the plots above (looks like air quality was really bad). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Mwp_WIRM1xy"
      },
      "outputs": [],
      "source": [
        "# create a variable with the date of interest, September 9th 2020. \n",
        "date='09-09-2020'\n",
        "\n",
        "# filter the original dataframe using this date\n",
        "one_day=df[df['Date']==date]\n",
        "\n",
        "# create a scatterplot of sensor locations using latitude and longitude \n",
        "plt.scatter(\n",
        "    x=one_day['longitude'],\n",
        "    y=one_day['latitude'])\n",
        "\n",
        "# as always, label our axes and the plot!\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.title(\"Geographic Distribution of AQI sensors in California\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgyzfdrMvBI6"
      },
      "source": [
        "If you close your eyes and imagine the shape of California, you can probably see its outline roughly traced in the points above. This plot leaves a number of things to be desired. \n",
        "\n",
        "### Basemaps \n",
        "\n",
        "First, we may want to add in a base map of some kind so we can have a better sense of where each sensor is. For this, we have to import an extra library called \"Basemap\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsnO-aII0MZg"
      },
      "outputs": [],
      "source": [
        "# import Basemap library\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "\n",
        "# create a basemap, call it 'map'\n",
        "map = Basemap(projection='lcc', resolution='l', # this selects the projection of the map.\n",
        "            lat_0=37.5, lon_0=-119, # this sets the center of the map \n",
        "            width=1E6, height=1.2E6) # this sets the window that we're looking at, in meters.\n",
        "\n",
        "# We can add features to our blank basemap, including coastlines, as well as state and country boundaries. \n",
        "map.drawcoastlines(color='black')\n",
        "map.drawcountries(color='black')\n",
        "map.drawstates(color='gray')\n",
        "\n",
        "# Finally, we add in our AQI sensor data on top of the basemap.\n",
        "map.scatter(\n",
        "    one_day['longitude'], \n",
        "    one_day['latitude'], \n",
        "    latlon=True)\n",
        "\n",
        "# as always, title your figure\n",
        "plt.title(\"Geographic Distribution of AQI sensors in California\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlaY4k7E2pXi"
      },
      "source": [
        "That's looking a bit better! We now have a much better sense of the actual distribution of these sensors within california. People who know the area will recognize clusters of sensors around San Francisco and Los Angeles; This makes sense, given that these areas have a higher population density. However, our plot is still missing some pretty important information: the actual AQI readings! \n",
        "\n",
        "### Colormaps\n",
        "\n",
        "The whole point of plotting these sensors is to understand the spatial distribution of air pollution from the 2020 wildfires. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnwnddrWv-Qp"
      },
      "source": [
        "The EPA published the following [table](https://www.airnow.gov/aqi/aqi-basics/) on their website, which creates a color-coded scale of AQI values that corresponds to the impact thereof on human health. \n",
        "\n",
        "- AQI under 50 is colored green, and indicates \"Good\" air quality. \n",
        "- AQI between 100 and 200 is generally unhealthy \n",
        "- AQI over 300 is deemed hazardous. \n",
        "\n",
        "With this in mind, quickly scroll back up to the AQI plots over time. If you did everything correctly, you should notice that the *average* AQI value across all sensors in the worst affected county was over 600! \n",
        "\n",
        "We'll be using the table from the EPA website to build our own color map. In the code below, I scrape the table and turn it into a \"colormap\" (basically, a dictionary that associates numbers with colors) that we'll use to color the AQI sensors later. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_srXcvBR4qm"
      },
      "outputs": [],
      "source": [
        "# scrape the table of AQI values and corresponding colors \n",
        "# save it as a dataframe called colors\n",
        "colors=pd.read_html('https://www.airnow.gov/aqi/aqi-basics/')[0]\n",
        "\n",
        "# create a numerical column for AQI values by splitting the test in the \"values of index\" column. \n",
        "# pull out the first string, and convert it to integer\n",
        "colors['aqi']=colors['Values of Index'].str.split(' ').str[0].astype(int)\n",
        "\n",
        "# print three columns from the dataframe \n",
        "print(colors[['aqi','Daily AQI Color','Levels of Concern']])\n",
        "\n",
        "# create a \"colormap\" from this dataframe using the \"Daily AQI Color\" column, and the \"aqi\" column \n",
        "aqi_colors=matplotlib.colors.LinearSegmentedColormap.from_list(colors['aqi'],colors['Daily AQI Color'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnBXdOjMw8l0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4b2yhL94Rdq"
      },
      "source": [
        "Now, we can use this \"aqi_colors\" object as a color palette later when we plot the AQI sensors. This way, we will know that green and yellow points are OK, while red and purple points represent hazardous levels of air pollution. I've annotated the code above, but it's ok if you don't get all of it. You could simply load a different colormap in one line of code; check out the documentation [here](https://matplotlib.org/stable/tutorials/colors/colormaps.html). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAhoFnTwBCEB"
      },
      "outputs": [],
      "source": [
        "map = Basemap(projection='lcc', resolution='l', \n",
        "            lat_0=37.5, lon_0=-119,\n",
        "            width=1E6, height=1.2E6)\n",
        "\n",
        "map.drawcoastlines(color='black')\n",
        "map.drawcountries(color='black')\n",
        "map.drawstates(color='gray')\n",
        "\n",
        "map.scatter(\n",
        "      one_day['longitude'], \n",
        "      one_day['latitude'], \n",
        "      latlon=True, \n",
        "      c=one_day['AQI'], # We're adding that \n",
        "      cmap=aqi_colors, \n",
        "      vmin=0, \n",
        "      vmax=300)\n",
        "\n",
        "\n",
        "plt.title('Air Quality on September 9th, 2020')\n",
        "plt.colorbar(label='Air Quality Index');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR8xWg2yojZx"
      },
      "source": [
        "This plot gives us a good sense of which areas were worst affected by the wildfires on September 9th, 2020. Areas in the central valley suffered particularly bad air quality, with AQI reaching hazardous levels in some areas. \n",
        "\n",
        "### Exercise\n",
        "\n",
        "So far, we've been plotting data from one day, using a dataframe we generated by filtering the date column like so: `one_day=df[df['Date']=='09-09-2020']` (date format is day-month-year).\n",
        "\n",
        "Using the code from the previous cell, generate a plot of AQI on March 2nd, 2020. After that, use the groupby function to generate a plot of the maximum AQI reading for each sensor and plot it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk5UEgvBpQKY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ5lQ_tAoD3C"
      },
      "source": [
        "If you've followed along this far, well done! we've come a long way from a spreadsheet full of sensor readings. But we can go even further!\n",
        "\n",
        "## Advanced: Satellite Imagery and Interactivity\n",
        "\n",
        "The AQI plots we've generated above give us a good sense of where the worst air pollution was on a given day; but we're still basically *inferring* the presence of fires. Luckily, we don't have to do that. The plumes of smoke generated by the fires were so vast that they were visible from space. There are a variety of satellites that image the earth each day (some, like GOES-17, take a picture every few minutes!).\n",
        "\n",
        "NASA's Moderate Resolution Imaging Spectroradiometer (MODIS) satellites take a picture of the same spot on earth nearly every day. So far, we've been looking at September 9th as a particularly bad day for air quality in California. Let's have a look at a satellite image from that day. A Python library called ipyleaflet contains some useful functions that let us pull up an interactive map of satellite imagery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODtN3RzS7mTO"
      },
      "outputs": [],
      "source": [
        "# import the map making modules from ipyleaflet\n",
        "from ipyleaflet import Map, Marker, basemaps, basemap_to_tiles,Circle\n",
        "\n",
        "# let create an interactive Map object called \"satellite_map\"\n",
        "satellite_map = Map(\n",
        "  basemap=basemap_to_tiles( #this function lets us pick from a list of basemaps for our interactive map\n",
        "    basemaps.NASAGIBS.ModisTerraTrueColorCR, \"2020-09-09\" # here we're specifying that we want MODIS imagery, and the date that we want it from  \n",
        "  ),\n",
        "  center=(36.77, -119.41), # then, we want to center the map on california. these coordinates do that\n",
        "  zoom=5, #finally, we want to set the zoom level of the map. \n",
        ")\n",
        "\n",
        "# once we've created the map object we can make it bigger or smaller. let's make it 700 pixels tall. \n",
        "satellite_map.layout.height = '700px'\n",
        "\n",
        "# now, we visualize it.\n",
        "satellite_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jPv5Co7xBfZ"
      },
      "source": [
        "This is a pretty striking image of the West Coast of the U.S. We can see fluffy white clouds to the East and West, but in the center of the map plumes of brown smoke emanate from wildfires in California and Oregon. Use the + - keys in the top left to zoom in, see if you can spot some wildfires. \n",
        "\n",
        "### Exercise\n",
        "\n",
        "Try changing the code in the cell above to display an image from September 15th. You could even try importing a different basemap (like nighttime lights) using this [list of basemaps](https://ipyleaflet.readthedocs.io/en/latest/map_and_basemaps/basemaps.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks1pMWnwrZuM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soBfBHT7rabc"
      },
      "source": [
        "## Combining sensors and satellite images \n",
        "\n",
        "A cool part of working with spatial data is that we can combine two completeley different datasets using spatial information. We can add the AQI sensor data as points to this map. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXoox6k4xa9x"
      },
      "outputs": [],
      "source": [
        "# grab the first row from our September 9th dataframe\n",
        "row=one_day.iloc[0]\n",
        "print(row)\n",
        "\n",
        "# This part uses the AQI value in this row (72), and looks up the corresponding color in the colormap we created earlier \n",
        "color=matplotlib.colors.rgb2hex(aqi_colors(row['AQI']))\n",
        "\n",
        "# Now we create a Circle object using the latitude and longitude from the row, and color it using the color we just selected\n",
        "point=Circle(location=(row['latitude'],row['longitude']), color=color)\n",
        "\n",
        "# Add this as a layer to the satellite_map object\n",
        "satellite_map.add_layer(point)\n",
        "\n",
        "# Display the updated map\n",
        "satellite_map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtBUwL15tzrc"
      },
      "source": [
        "It's a bit hard to see, but we've plotted an AQI sensor! its under the cloud of smoke in the center of the map. You can zoom in to get a closer look. looks like AQI was pretty bad at this location. \n",
        "\n",
        "Having plotted one point, we can now plot all the points on September 9th! to do so, we can use the `iterrows` function in Pandas which, suprisingly, lets you iterate over rows in a dataframe. The first line of code below allows us to iterate over the rows in the `one_day` dataframe. It will then run everything in the indented block for each row; in other words, for each row, it will:\n",
        "\n",
        "  1. use the row's value in the AQI value to select a color for the point \n",
        "  2. create a point object using the latitude and longitude columns\n",
        "  3. add that point to the satellite map. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znxAhhrmn84a"
      },
      "outputs": [],
      "source": [
        "for index, row in one_day.iterrows():\n",
        "  color=matplotlib.colors.rgb2hex(aqi_colors(row['AQI']))\n",
        "  point=Circle(location=(row['latitude'],row['longitude']), color=color)\n",
        "  satellite_map.add_layer(point)\n",
        "\n",
        "# display the map\n",
        "satellite_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPQZtXRBvoHJ"
      },
      "source": [
        "Theres a pretty striking trend in this data. If you zoom in, you'll see that the AQI sensors to the East are all green since they are up-wind from the fires. A few kilometers downwind of the fires, the AQI sensors display very high readings. Remember, our AQI data and the satellite imagery are derived from totally different sources, and are totally different types of data, but they seem to be telling us the same story. They actually complement each other in important ways. In our original plot of the AQI sensors without satellite imagery, we could tell that there was bad air quality on September 9th, but some sensors were green and others were red. The satellite image shows us that the variation in AQI across California on September 9th was due to the direction of the wind, blowing the smoke from the wildfires westward. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1NHvaSsvLXh"
      },
      "source": [
        "## Extension\n",
        "\n",
        "Now, to save some hassle we can package all the code we used to generate this map into one clean function. Because we're effectively just changing the date, we can configure this function so that we can feed it a different date, and it will grab a satellite image and filter our dataframe for values occuring on that day. Then, we can draw a new map in one line of code. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHJ2INVmDK0K"
      },
      "outputs": [],
      "source": [
        "def satellite_plot(date):\n",
        "  \n",
        "  ymd=datetime.strptime(date, '%d-%m-%Y').strftime('%Y-%m-%d')\n",
        "\n",
        "  satellite_map = Map(\n",
        "    basemap=basemap_to_tiles(\n",
        "      basemaps.NASAGIBS.ModisTerraTrueColorCR, ymd\n",
        "    ),\n",
        "    center=(36.77, -119.41),\n",
        "    zoom=6,\n",
        "  )\n",
        "\n",
        "  satellite_map.layout.height = '700px'\n",
        "\n",
        "  one_day=df[df['Date']==date]\n",
        "\n",
        "  for index, row in one_day.iterrows():\n",
        "    color=matplotlib.colors.rgb2hex(aqi_colors(row['AQI']))\n",
        "    point=Circle(location=(row['latitude'],row['longitude']), color=color)\n",
        "    satellite_map.add_layer(point)\n",
        "  return satellite_map\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdCesPNc9hQK"
      },
      "source": [
        "Now, we can simply change the date in the function and view both satellite imagery and AQI sensor data from a given day. Look at this clear day from February 3rd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Fj7NexYDHq2"
      },
      "outputs": [],
      "source": [
        "satellite_plot('02-03-2020')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buQATwoJ_MT3"
      },
      "source": [
        "All the AQI sensors are showing green values, indicating generally good air quality. The satellite image shows a few wispy clouds, but no thick yellow smoke. Now change the date to September 15th, and see what happens! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1A4_qH2_RkD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit ('3.9.5')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "d34fbd810dd9652f8e464616181cf14dbb258b5c046bed5c2f54c6b5e518fed2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}